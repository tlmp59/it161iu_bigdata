{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, count, when\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import col, monotonically_increasing_id, lit, date_add, explode\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import plotly.express as px\n",
    "from pyspark.ml.evaluation import  MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier,GBTClassifier,MultilayerPerceptronClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "# Define categorical and numerical columns\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/21 09:38:40 WARN Utils: Your hostname, Khim3 resolves to a loopback address: 127.0.1.1; using 10.0.120.234 instead (on interface wlo1)\n",
      "25/02/21 09:38:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/21 09:38:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(master = 'local')\n",
    "spark = SparkSession.builder \\\n",
    "          .appName(\"Python Spark Classifier\") \\\n",
    "          .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/21 09:38:54 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "|step|    type|  amount|   nameOrig|oldbalanceOrg|newbalanceOrig|   nameDest|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|\n",
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "|   1| PAYMENT| 9839.64|C1231006815|     170136.0|     160296.36|M1979787155|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT| 1864.28|C1666544295|      21249.0|      19384.72|M2044282225|           0.0|           0.0|      0|             0|\n",
      "|   1|TRANSFER|   181.0|C1305486145|        181.0|           0.0| C553264065|           0.0|           0.0|      1|             0|\n",
      "|   1|CASH_OUT|   181.0| C840083671|        181.0|           0.0|  C38997010|       21182.0|           0.0|      1|             0|\n",
      "|   1| PAYMENT|11668.14|C2048537720|      41554.0|      29885.86|M1230701703|           0.0|           0.0|      0|             0|\n",
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df  = spark.read.csv('data.csv', header=True, inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- step: integer (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- nameOrig: string (nullable = true)\n",
      " |-- oldbalanceOrg: double (nullable = true)\n",
      " |-- newbalanceOrig: double (nullable = true)\n",
      " |-- nameDest: string (nullable = true)\n",
      " |-- oldbalanceDest: double (nullable = true)\n",
      " |-- newbalanceDest: double (nullable = true)\n",
      " |-- isFraud: integer (nullable = true)\n",
      " |-- isFlaggedFraud: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Summary of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/21 09:38:55 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 3:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------+-----------------+-----------+-----------------+------------------+-----------+------------------+------------------+--------------------+--------------------+\n",
      "|summary|              step|    type|           amount|   nameOrig|    oldbalanceOrg|    newbalanceOrig|   nameDest|    oldbalanceDest|    newbalanceDest|             isFraud|      isFlaggedFraud|\n",
      "+-------+------------------+--------+-----------------+-----------+-----------------+------------------+-----------+------------------+------------------+--------------------+--------------------+\n",
      "|  count|           6362620| 6362620|          6362620|    6362620|          6362620|           6362620|    6362620|           6362620|           6362620|             6362620|             6362620|\n",
      "|   mean|243.39724563151657|    NULL|179861.9035491287|       NULL|833883.1040744764| 855113.6685785812|       NULL|1100701.6665196533|1224996.3982019224|0.001290820448180152| 2.51468734577894E-6|\n",
      "| stddev|142.33197104913066|    NULL|603858.2314629209|       NULL|2888242.673037527|2924048.5029542595|       NULL|3399180.1129944525|3674128.9421196915|0.035904796801604424|0.001585774705736...|\n",
      "|    min|                 1| CASH_IN|              0.0|C1000000639|              0.0|               0.0|C1000004082|               0.0|               0.0|                   0|                   0|\n",
      "|    25%|               156|    NULL|         13392.65|       NULL|              0.0|               0.0|       NULL|               0.0|               0.0|                   0|                   0|\n",
      "|    50%|               239|    NULL|         74864.38|       NULL|          14205.0|               0.0|       NULL|         132710.96|         214605.81|                   0|                   0|\n",
      "|    75%|               335|    NULL|        208699.28|       NULL|         107301.0|         144212.66|       NULL|         943027.78|        1111611.51|                   0|                   0|\n",
      "|    max|               743|TRANSFER|    9.244551664E7| C999999784|    5.958504037E7|     4.958504037E7| M999999784|    3.5601588935E8|    3.5617927892E8|                   1|                   1|\n",
      "+-------+------------------+--------+-----------------+-----------+-----------------+------------------+-----------+------------------+------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+--------+-------------+--------------+--------+--------------+--------------+-------+--------------+\n",
      "|step|type|amount|nameOrig|oldbalanceOrg|newbalanceOrig|nameDest|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|\n",
      "+----+----+------+--------+-------------+--------------+--------+--------------+--------------+-------+--------------+\n",
      "|   0|   0|     0|       0|            0|             0|       0|             0|             0|      0|             0|\n",
      "+----+----+------+--------+-------------+--------------+--------+--------------+--------------+-------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "duplicate_count = df.groupBy(df.columns).count().where(\"count > 1\").select(count(\"*\")).collect()[0][0]\n",
    "print(f\"Number of duplicate rows: {duplicate_count}\")\n",
    "df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['step',\n",
       " 'type',\n",
       " 'amount',\n",
       " 'origin',\n",
       " 'sender_old_balance',\n",
       " 'sender_new_balance',\n",
       " 'destination',\n",
       " 'receiver_old_balance',\n",
       " 'receiver_new_balance',\n",
       " 'isfraud',\n",
       " 'isFlaggedFraud']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    df.withColumnRenamed('nameOrig', 'origin')\n",
    "       .withColumnRenamed('oldbalanceOrg', 'sender_old_balance')\n",
    "       .withColumnRenamed('newbalanceOrig', 'sender_new_balance')\n",
    "       .withColumnRenamed('nameDest', 'destination')\n",
    "       .withColumnRenamed('oldbalanceDest', 'receiver_old_balance')\n",
    "       .withColumnRenamed('newbalanceDest', 'receiver_new_balance')\n",
    "       .withColumnRenamed('isFraud', 'isfraud')\n",
    ")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop column isFlaggedFraud\n",
    "\n",
    "df = df.drop('isFlaggedFraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------+\n",
      "|isfraud|    type|  count|\n",
      "+-------+--------+-------+\n",
      "|      0| CASH_IN|1399284|\n",
      "|      0|CASH_OUT|2233384|\n",
      "|      0|   DEBIT|  41432|\n",
      "|      0| PAYMENT|2151495|\n",
      "|      0|TRANSFER| 528812|\n",
      "|      1|CASH_OUT|   4116|\n",
      "|      1|TRANSFER|   4097|\n",
      "+-------+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"isfraud\", \"type\").count().orderBy(\"isfraud\", \"type\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------+-----------+------------------+------------------+-----------+--------------------+--------------------+-------+-----+\n",
      "|step|    type|  amount|     origin|sender_old_balance|sender_new_balance|destination|receiver_old_balance|receiver_new_balance|isfraud|type2|\n",
      "+----+--------+--------+-----------+------------------+------------------+-----------+--------------------+--------------------+-------+-----+\n",
      "|   1| PAYMENT| 9839.64|C1231006815|          170136.0|         160296.36|M1979787155|                 0.0|                 0.0|      0|   CM|\n",
      "|   1| PAYMENT| 1864.28|C1666544295|           21249.0|          19384.72|M2044282225|                 0.0|                 0.0|      0|   CM|\n",
      "|   1|TRANSFER|   181.0|C1305486145|             181.0|               0.0| C553264065|                 0.0|                 0.0|      1|   CC|\n",
      "|   1|CASH_OUT|   181.0| C840083671|             181.0|               0.0|  C38997010|             21182.0|                 0.0|      1|   CC|\n",
      "|   1| PAYMENT|11668.14|C2048537720|           41554.0|          29885.86|M1230701703|                 0.0|                 0.0|      0|   CM|\n",
      "+----+--------+--------+-----------+------------------+------------------+-----------+--------------------+--------------------+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\n",
    "    \"type2\",\n",
    "    when((col(\"origin\").contains(\"C\")) & (col(\"destination\").contains(\"C\")), \"CC\")\n",
    "    .when((col(\"origin\").contains(\"C\")) & (col(\"destination\").contains(\"M\")), \"CM\")\n",
    "    .when((col(\"origin\").contains(\"M\")) & (col(\"destination\").contains(\"C\")), \"MC\")\n",
    "    .when((col(\"origin\").contains(\"M\")) & (col(\"destination\").contains(\"M\")), \"MM\")\n",
    "    .otherwise(None)\n",
    ")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fraud transactions according to type are below:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|type2|count|\n",
      "+-----+-----+\n",
      "|   CC| 8213|\n",
      "+-----+-----+\n",
      "\n",
      "Number of valid transactions according to type are below:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|type2|  count|\n",
      "+-----+-------+\n",
      "|   CC|4202912|\n",
      "|   CM|2151495|\n",
      "+-----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fraud_trans = df.filter(col(\"isfraud\") == 1)\n",
    "valid_trans = df.filter(col(\"isfraud\") == 0)\n",
    "\n",
    "# Count occurrences of each type2 category for fraud transactions\n",
    "print(\"Number of fraud transactions according to type are below:\")\n",
    "fraud_trans.groupBy(\"type2\").agg(count(\"*\").alias(\"count\")).orderBy(col(\"count\").desc()).show()\n",
    "\n",
    "# Count occurrences of each type2 category for valid transactions\n",
    "print(\"Number of valid transactions according to type are below:\")\n",
    "valid_trans.groupBy(\"type2\").agg(count(\"*\").alias(\"count\")).orderBy(col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---------+------------------+------------------+--------------------+--------------------+-------+-----+\n",
      "|step|    type|   amount|sender_old_balance|sender_new_balance|receiver_old_balance|receiver_new_balance|isfraud|type2|\n",
      "+----+--------+---------+------------------+------------------+--------------------+--------------------+-------+-----+\n",
      "|   1| PAYMENT|  9839.64|          170136.0|         160296.36|                 0.0|                 0.0|      0|   CM|\n",
      "|   1| PAYMENT|  1864.28|           21249.0|          19384.72|                 0.0|                 0.0|      0|   CM|\n",
      "|   1|TRANSFER|    181.0|             181.0|               0.0|                 0.0|                 0.0|      1|   CC|\n",
      "|   1|CASH_OUT|    181.0|             181.0|               0.0|             21182.0|                 0.0|      1|   CC|\n",
      "|   1| PAYMENT| 11668.14|           41554.0|          29885.86|                 0.0|                 0.0|      0|   CM|\n",
      "|   1| PAYMENT|  7817.71|           53860.0|          46042.29|                 0.0|                 0.0|      0|   CM|\n",
      "|   1| PAYMENT|  7107.77|          183195.0|         176087.23|                 0.0|                 0.0|      0|   CM|\n",
      "|   1| PAYMENT|  7861.64|         176087.23|         168225.59|                 0.0|                 0.0|      0|   CM|\n",
      "|   1| PAYMENT|  4024.36|            2671.0|               0.0|                 0.0|                 0.0|      0|   CM|\n",
      "|   1|   DEBIT|  5337.77|           41720.0|          36382.23|             41898.0|            40348.79|      0|   CC|\n",
      "|   1|   DEBIT|  9644.94|            4465.0|               0.0|             10845.0|           157982.12|      0|   CC|\n",
      "|   1| PAYMENT|  3099.97|           20771.0|          17671.03|                 0.0|                 0.0|      0|   CM|\n",
      "|   1| PAYMENT|  2560.74|            5070.0|           2509.26|                 0.0|                 0.0|      0|   CM|\n",
      "|   1| PAYMENT| 11633.76|           10127.0|               0.0|                 0.0|                 0.0|      0|   CM|\n",
      "|   1| PAYMENT|  4098.78|          503264.0|         499165.22|                 0.0|                 0.0|      0|   CM|\n",
      "|   1|CASH_OUT|229133.94|           15325.0|               0.0|              5083.0|            51513.44|      0|   CC|\n",
      "|   1| PAYMENT|  1563.82|             450.0|               0.0|                 0.0|                 0.0|      0|   CM|\n",
      "|   1| PAYMENT|  1157.86|           21156.0|          19998.14|                 0.0|                 0.0|      0|   CM|\n",
      "|   1| PAYMENT|   671.64|           15123.0|          14451.36|                 0.0|                 0.0|      0|   CM|\n",
      "|   1|TRANSFER| 215310.3|             705.0|               0.0|             22425.0|                 0.0|      0|   CC|\n",
      "+----+--------+---------+------------------+------------------+--------------------+--------------------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop 'origin' and 'destination' columns\n",
    "df = df.drop(\"origin\", \"destination\")\n",
    "\n",
    "# Show the updated DataFrame\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- step: integer (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- sender_old_balance: double (nullable = true)\n",
      " |-- sender_new_balance: double (nullable = true)\n",
      " |-- receiver_old_balance: double (nullable = true)\n",
      " |-- receiver_new_balance: double (nullable = true)\n",
      " |-- isfraud: integer (nullable = true)\n",
      " |-- type2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "label_indexer = StringIndexer(inputCol=\"isfraud\", outputCol=\"label\")\n",
    "df = label_indexer.fit(df).transform(df)\n",
    "\n",
    "categorical_cols = [\"type\", \"type2\"]\n",
    "numerical_cols = [\"amount\", \"sender_old_balance\", \"sender_new_balance\",\n",
    "                  \"receiver_old_balance\", \"receiver_new_balance\"]\n",
    "\n",
    "# Pipeline stages\n",
    "stages = []\n",
    "\n",
    "# StringIndexer and OneHotEncoder for categorical features\n",
    "for col in categorical_cols:\n",
    "    indexer = StringIndexer(inputCol=col, outputCol=f\"indexed_{col}\")\n",
    "    encoder = OneHotEncoder(inputCol=f\"indexed_{col}\", outputCol=f\"encoded_{col}\")\n",
    "    stages.extend([indexer, encoder])\n",
    "\n",
    "# Assemble all features into a single vector\n",
    "assembler_inputs = [f\"encoded_{col}\" for col in categorical_cols] + numerical_cols\n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
    "stages.append(assembler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/21 09:42:40 WARN MemoryStore: Not enough space to cache rdd_131_3 in memory! (computed 70.0 MiB so far)\n",
      "25/02/21 09:42:40 WARN BlockManager: Persisting block rdd_131_3 to disk instead.\n",
      "25/02/21 09:43:22 WARN MemoryStore: Not enough space to cache rdd_197_3 in memory! (computed 70.0 MiB so far)\n",
      "25/02/21 09:43:22 WARN BlockManager: Persisting block rdd_197_3 to disk instead.\n",
      "25/02/21 09:43:47 WARN MemoryStore: Not enough space to cache rdd_258_3 in memory! (computed 70.0 MiB so far)\n",
      "25/02/21 09:43:47 WARN BlockManager: Persisting block rdd_258_3 to disk instead.\n",
      "25/02/21 09:44:11 WARN MemoryStore: Not enough space to cache rdd_322_3 in memory! (computed 70.0 MiB so far)\n",
      "25/02/21 09:44:11 WARN BlockManager: Persisting block rdd_322_3 to disk instead.\n",
      "25/02/21 09:44:52 WARN MemoryStore: Not enough space to cache rdd_391_3 in memory! (computed 70.0 MiB so far)\n",
      "25/02/21 09:44:52 WARN BlockManager: Persisting block rdd_391_3 to disk instead.\n",
      "25/02/21 09:45:32 WARN MemoryStore: Not enough space to cache rdd_457_3 in memory! (computed 70.0 MiB so far)\n",
      "25/02/21 09:45:32 WARN BlockManager: Persisting block rdd_457_3 to disk instead.\n",
      "25/02/21 09:45:55 WARN MemoryStore: Not enough space to cache rdd_518_3 in memory! (computed 70.0 MiB so far)\n",
      "25/02/21 09:45:55 WARN BlockManager: Persisting block rdd_518_3 to disk instead.\n",
      "25/02/21 09:46:17 WARN MemoryStore: Not enough space to cache rdd_582_3 in memory! (computed 70.0 MiB so far)\n",
      "25/02/21 09:46:17 WARN BlockManager: Persisting block rdd_582_3 to disk instead.\n",
      "25/02/21 09:46:57 WARN MemoryStore: Not enough space to cache rdd_651_3 in memory! (computed 70.0 MiB so far)\n",
      "25/02/21 09:46:57 WARN BlockManager: Persisting block rdd_651_3 to disk instead.\n",
      "25/02/21 09:47:36 WARN MemoryStore: Not enough space to cache rdd_717_3 in memory! (computed 70.0 MiB so far)\n",
      "25/02/21 09:47:36 WARN BlockManager: Persisting block rdd_717_3 to disk instead.\n",
      "25/02/21 09:48:00 WARN MemoryStore: Not enough space to cache rdd_778_3 in memory! (computed 70.0 MiB so far)\n",
      "25/02/21 09:48:00 WARN BlockManager: Persisting block rdd_778_3 to disk instead.\n",
      "25/02/21 09:48:25 WARN MemoryStore: Not enough space to cache rdd_842_3 in memory! (computed 70.0 MiB so far)\n",
      "25/02/21 09:48:25 WARN BlockManager: Persisting block rdd_842_3 to disk instead.\n",
      "25/02/21 09:50:06 WARN MemoryStore: Not enough space to cache rdd_903_0 in memory! (computed 157.6 MiB so far)\n",
      "25/02/21 09:50:06 WARN BlockManager: Persisting block rdd_903_0 to disk instead.\n",
      "25/02/21 09:50:14 WARN MemoryStore: Not enough space to cache rdd_903_1 in memory! (computed 157.6 MiB so far)\n",
      "25/02/21 09:50:14 WARN BlockManager: Persisting block rdd_903_1 to disk instead.\n",
      "25/02/21 09:50:16 WARN MemoryStore: Not enough space to cache rdd_903_1 in memory! (computed 166.4 MiB so far)\n",
      "25/02/21 09:50:22 WARN MemoryStore: Not enough space to cache rdd_903_2 in memory! (computed 157.6 MiB so far)\n",
      "25/02/21 09:50:22 WARN BlockManager: Persisting block rdd_903_2 to disk instead.\n",
      "25/02/21 09:50:23 WARN MemoryStore: Not enough space to cache rdd_903_2 in memory! (computed 166.4 MiB so far)\n",
      "25/02/21 09:50:27 WARN MemoryStore: Not enough space to cache rdd_903_3 in memory! (computed 70.0 MiB so far)\n",
      "25/02/21 09:50:27 WARN BlockManager: Persisting block rdd_903_3 to disk instead.\n",
      "25/02/21 09:50:29 WARN MemoryStore: Not enough space to cache rdd_903_1 in memory! (computed 104.8 MiB so far)\n",
      "25/02/21 09:50:30 WARN MemoryStore: Not enough space to cache rdd_903_2 in memory! (computed 104.8 MiB so far)\n",
      "[Stage 274:==========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.9984\n",
      "Accuracy: 0.9988\n",
      "Precision: 0.9988\n",
      "Recall: 0.9988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'F1-Score': 0.9983706186672047,\n",
       " 'Accuracy': 0.998821021477674,\n",
       " 'Precision': 0.9988224117202781,\n",
       " 'Recall': 0.998821021477674}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(labelCol=\"isfraud\", featuresCol=\"features\", seed=42)\n",
    "stages.append(dt_classifier)\n",
    "\n",
    "# Create a Pipeline\n",
    "pipeline = Pipeline(stages=stages)\n",
    "\n",
    "# Split data into training and test sets (stratified split)\n",
    "training, test = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Parameter grid for cross-validation (hyperparameter tuning)\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(dt_classifier.maxDepth, [1,2]) \\\n",
    "    .addGrid(dt_classifier.maxBins, [32, 64]) \\\n",
    "    .build()\n",
    "\n",
    "# Train the cross-validated model (F1 as the optimization metric)\n",
    "cv = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"isfraud\", metricName=\"f1\"),\n",
    "    numFolds=3\n",
    ")\n",
    "\n",
    "cv_model = cv.fit(training)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = cv_model.transform(test)\n",
    "\n",
    "# Define evaluators for different metrics\n",
    "evaluators = {\n",
    "    \"F1-Score\": MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"isfraud\", metricName=\"f1\"),\n",
    "    \"Accuracy\": MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"isfraud\", metricName=\"accuracy\"),\n",
    "    \"Precision\": MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"isfraud\", metricName=\"weightedPrecision\"),\n",
    "    \"Recall\": MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"isfraud\", metricName=\"weightedRecall\")\n",
    "}\n",
    "\n",
    "# Compute and print all evaluation metrics\n",
    "metrics = {metric_name: evaluator.evaluate(predictions) for metric_name, evaluator in evaluators.items()}\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define MLP model with hidden layers\n",
    "# mlp_classifier = MultilayerPerceptronClassifier(labelCol=\"isfraud\", featuresCol=\"features\", maxIter=100, layers=[len(assembler_inputs), 8, 2], seed=42)\n",
    "\n",
    "# # Add model to the pipeline\n",
    "# mlp_pipeline = Pipeline(stages=stages + [mlp_classifier])\n",
    "\n",
    "# # Hyperparameter tuning grid\n",
    "# mlp_param_grid = ParamGridBuilder() \\\n",
    "#     .addGrid(mlp_classifier.maxIter, [50, 100]) \\\n",
    "#     .build()\n",
    "\n",
    "# # Cross-validation\n",
    "# mlp_cv = CrossValidator(\n",
    "#     estimator=mlp_pipeline,\n",
    "#     estimatorParamMaps=mlp_param_grid,\n",
    "#     evaluator=MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"isfraud\", metricName=\"f1\"),\n",
    "#     numFolds=3\n",
    "# )\n",
    "\n",
    "# # Train model\n",
    "# mlp_cv_model = mlp_cv.fit(training)\n",
    "\n",
    "# # Make predictions\n",
    "# mlp_predictions = mlp_cv_model.transform(test)\n",
    "\n",
    "# # Evaluate metrics\n",
    "# mlp_metrics = {metric: MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"isfraud\", metricName=metric.lower()).evaluate(mlp_predictions) for metric in [\"F1-Score\", \"Accuracy\", \"Precision\", \"Recall\"]}\n",
    "\n",
    "# # Print metrics\n",
    "# print(\"\\n🔍 Multilayer Perceptron Metrics:\")\n",
    "# for metric, value in mlp_metrics.items():\n",
    "#     print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# mlp_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define GBT model\n",
    "# gbt_classifier = GBTClassifier(labelCol=\"isfraud\", featuresCol=\"features\", seed=42)\n",
    "\n",
    "# # Add model to the pipeline\n",
    "# gbt_pipeline = Pipeline(stages=stages + [gbt_classifier])\n",
    "\n",
    "# # Hyperparameter tuning grid\n",
    "# gbt_param_grid = ParamGridBuilder() \\\n",
    "#     .addGrid(gbt_classifier.maxDepth, [3, 5]) \\\n",
    "#     .addGrid(gbt_classifier.maxIter, [20, 50]) \\\n",
    "#     .build()\n",
    "\n",
    "# # Cross-validation\n",
    "# gbt_cv = CrossValidator(\n",
    "#     estimator=gbt_pipeline,\n",
    "#     estimatorParamMaps=gbt_param_grid,\n",
    "#     evaluator=MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"isfraud\", metricName=\"f1\"),\n",
    "#     numFolds=3\n",
    "# )\n",
    "\n",
    "# # Train model\n",
    "# gbt_cv_model = gbt_cv.fit(training)\n",
    "\n",
    "# # Make predictions\n",
    "# gbt_predictions = gbt_cv_model.transform(test)\n",
    "\n",
    "# # Evaluate metrics\n",
    "# gbt_metrics = {metric: MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"isfraud\", metricName=metric.lower()).evaluate(gbt_predictions) for metric in [\"F1-Score\", \"Accuracy\", \"Precision\", \"Recall\"]}\n",
    "\n",
    "# # Print metrics\n",
    "# print(\"\\n🔍 Gradient-Boosted Trees Metrics:\")\n",
    "# for metric, value in gbt_metrics.items():\n",
    "#     print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# gbt_metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
