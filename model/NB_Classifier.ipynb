{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, count, when\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import col, monotonically_increasing_id, lit, date_add, explode\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import plotly.express as px\n",
    "from pyspark.ml.evaluation import  MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier,GBTClassifier,MultilayerPerceptronClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "# Define categorical and numerical columns\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/21 15:38:15 WARN Utils: Your hostname, Khim3 resolves to a loopback address: 127.0.1.1; using 10.0.120.234 instead (on interface wlo1)\n",
      "25/02/21 15:38:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/21 15:38:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(master = 'local')\n",
    "spark = SparkSession.builder \\\n",
    "          .appName(\"Python Spark Classifier\") \\\n",
    "          .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "|step|    type|  amount|   nameOrig|oldbalanceOrg|newbalanceOrig|   nameDest|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|\n",
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "|   1| PAYMENT| 9839.64|C1231006815|     170136.0|     160296.36|M1979787155|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT| 1864.28|C1666544295|      21249.0|      19384.72|M2044282225|           0.0|           0.0|      0|             0|\n",
      "|   1|TRANSFER|   181.0|C1305486145|        181.0|           0.0| C553264065|           0.0|           0.0|      1|             0|\n",
      "|   1|CASH_OUT|   181.0| C840083671|        181.0|           0.0|  C38997010|       21182.0|           0.0|      1|             0|\n",
      "|   1| PAYMENT|11668.14|C2048537720|      41554.0|      29885.86|M1230701703|           0.0|           0.0|      0|             0|\n",
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df  = spark.read.csv('data.csv', header=True, inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- step: integer (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- nameOrig: string (nullable = true)\n",
      " |-- oldbalanceOrg: double (nullable = true)\n",
      " |-- newbalanceOrig: double (nullable = true)\n",
      " |-- nameDest: string (nullable = true)\n",
      " |-- oldbalanceDest: double (nullable = true)\n",
      " |-- newbalanceDest: double (nullable = true)\n",
      " |-- isFraud: integer (nullable = true)\n",
      " |-- isFlaggedFraud: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Summary of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/21 15:38:29 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "25/02/21 15:38:33 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "[Stage 3:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------+-----------------+-----------+-----------------+------------------+-----------+------------------+------------------+--------------------+--------------------+\n",
      "|summary|              step|    type|           amount|   nameOrig|    oldbalanceOrg|    newbalanceOrig|   nameDest|    oldbalanceDest|    newbalanceDest|             isFraud|      isFlaggedFraud|\n",
      "+-------+------------------+--------+-----------------+-----------+-----------------+------------------+-----------+------------------+------------------+--------------------+--------------------+\n",
      "|  count|           6362620| 6362620|          6362620|    6362620|          6362620|           6362620|    6362620|           6362620|           6362620|             6362620|             6362620|\n",
      "|   mean|243.39724563151657|    NULL|179861.9035491287|       NULL|833883.1040744764| 855113.6685785812|       NULL|1100701.6665196533|1224996.3982019224|0.001290820448180152| 2.51468734577894E-6|\n",
      "| stddev|142.33197104913066|    NULL|603858.2314629209|       NULL|2888242.673037527|2924048.5029542595|       NULL|3399180.1129944525|3674128.9421196915|0.035904796801604424|0.001585774705736...|\n",
      "|    min|                 1| CASH_IN|              0.0|C1000000639|              0.0|               0.0|C1000004082|               0.0|               0.0|                   0|                   0|\n",
      "|    25%|               156|    NULL|         13392.65|       NULL|              0.0|               0.0|       NULL|               0.0|               0.0|                   0|                   0|\n",
      "|    50%|               239|    NULL|         74864.38|       NULL|          14205.0|               0.0|       NULL|         132710.96|         214605.81|                   0|                   0|\n",
      "|    75%|               335|    NULL|        208699.28|       NULL|         107301.0|         144212.66|       NULL|         943027.78|        1111611.51|                   0|                   0|\n",
      "|    max|               743|TRANSFER|    9.244551664E7| C999999784|    5.958504037E7|     4.958504037E7| M999999784|    3.5601588935E8|    3.5617927892E8|                   1|                   1|\n",
      "+-------+------------------+--------+-----------------+-----------+-----------------+------------------+-----------+------------------+------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+--------+-------------+--------------+--------+--------------+--------------+-------+--------------+\n",
      "|step|type|amount|nameOrig|oldbalanceOrg|newbalanceOrig|nameDest|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|\n",
      "+----+----+------+--------+-------------+--------------+--------+--------------+--------------+-------+--------------+\n",
      "|   0|   0|     0|       0|            0|             0|       0|             0|             0|      0|             0|\n",
      "+----+----+------+--------+-------------+--------------+--------+--------------+--------------+-------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "duplicate_count = df.groupBy(df.columns).count().where(\"count > 1\").select(count(\"*\")).collect()[0][0]\n",
    "print(f\"Number of duplicate rows: {duplicate_count}\")\n",
    "df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['step',\n",
       " 'type',\n",
       " 'amount',\n",
       " 'origin',\n",
       " 'sender_old_balance',\n",
       " 'sender_new_balance',\n",
       " 'destination',\n",
       " 'receiver_old_balance',\n",
       " 'receiver_new_balance',\n",
       " 'isfraud',\n",
       " 'isFlaggedFraud']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    df.withColumnRenamed('nameOrig', 'origin')\n",
    "       .withColumnRenamed('oldbalanceOrg', 'sender_old_balance')\n",
    "       .withColumnRenamed('newbalanceOrig', 'sender_new_balance')\n",
    "       .withColumnRenamed('nameDest', 'destination')\n",
    "       .withColumnRenamed('oldbalanceDest', 'receiver_old_balance')\n",
    "       .withColumnRenamed('newbalanceDest', 'receiver_new_balance')\n",
    "       .withColumnRenamed('isFraud', 'isfraud')\n",
    ")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop column isFlaggedFraud\n",
    "\n",
    "df = df.drop('isFlaggedFraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------+\n",
      "|isfraud|    type|  count|\n",
      "+-------+--------+-------+\n",
      "|      0| CASH_IN|1399284|\n",
      "|      0|CASH_OUT|2233384|\n",
      "|      0|   DEBIT|  41432|\n",
      "|      0| PAYMENT|2151495|\n",
      "|      0|TRANSFER| 528812|\n",
      "|      1|CASH_OUT|   4116|\n",
      "|      1|TRANSFER|   4097|\n",
      "+-------+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"isfraud\", \"type\").count().orderBy(\"isfraud\", \"type\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------+-----------+------------------+------------------+-----------+--------------------+--------------------+-------+-----+\n",
      "|step|    type|  amount|     origin|sender_old_balance|sender_new_balance|destination|receiver_old_balance|receiver_new_balance|isfraud|type2|\n",
      "+----+--------+--------+-----------+------------------+------------------+-----------+--------------------+--------------------+-------+-----+\n",
      "|   1| PAYMENT| 9839.64|C1231006815|          170136.0|         160296.36|M1979787155|                 0.0|                 0.0|      0|   CM|\n",
      "|   1| PAYMENT| 1864.28|C1666544295|           21249.0|          19384.72|M2044282225|                 0.0|                 0.0|      0|   CM|\n",
      "|   1|TRANSFER|   181.0|C1305486145|             181.0|               0.0| C553264065|                 0.0|                 0.0|      1|   CC|\n",
      "|   1|CASH_OUT|   181.0| C840083671|             181.0|               0.0|  C38997010|             21182.0|                 0.0|      1|   CC|\n",
      "|   1| PAYMENT|11668.14|C2048537720|           41554.0|          29885.86|M1230701703|                 0.0|                 0.0|      0|   CM|\n",
      "+----+--------+--------+-----------+------------------+------------------+-----------+--------------------+--------------------+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\n",
    "    \"type2\",\n",
    "    when((col(\"origin\").contains(\"C\")) & (col(\"destination\").contains(\"C\")), \"CC\")\n",
    "    .when((col(\"origin\").contains(\"C\")) & (col(\"destination\").contains(\"M\")), \"CM\")\n",
    "    .when((col(\"origin\").contains(\"M\")) & (col(\"destination\").contains(\"C\")), \"MC\")\n",
    "    .when((col(\"origin\").contains(\"M\")) & (col(\"destination\").contains(\"M\")), \"MM\")\n",
    "    .otherwise(None)\n",
    ")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fraud transactions according to type are below:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|type2|count|\n",
      "+-----+-----+\n",
      "|   CC| 8213|\n",
      "+-----+-----+\n",
      "\n",
      "Number of valid transactions according to type are below:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|type2|  count|\n",
      "+-----+-------+\n",
      "|   CC|4202912|\n",
      "|   CM|2151495|\n",
      "+-----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fraud_trans = df.filter(col(\"isfraud\") == 1)\n",
    "valid_trans = df.filter(col(\"isfraud\") == 0)\n",
    "\n",
    "# Count occurrences of each type2 category for fraud transactions\n",
    "print(\"Number of fraud transactions according to type are below:\")\n",
    "fraud_trans.groupBy(\"type2\").agg(count(\"*\").alias(\"count\")).orderBy(col(\"count\").desc()).show()\n",
    "\n",
    "# Count occurrences of each type2 category for valid transactions\n",
    "print(\"Number of valid transactions according to type are below:\")\n",
    "valid_trans.groupBy(\"type2\").agg(count(\"*\").alias(\"count\")).orderBy(col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+---------+------------------+------------------+--------------------+--------------------+-------+-----+\n",
      "|step|    type|   amount|sender_old_balance|sender_new_balance|receiver_old_balance|receiver_new_balance|isfraud|type2|\n",
      "+----+--------+---------+------------------+------------------+--------------------+--------------------+-------+-----+\n",
      "|   1| PAYMENT|  9839.64|          170136.0|         160296.36|                 0.0|                 0.0|      0|   CM|\n",
      "|   1| PAYMENT|  1864.28|           21249.0|          19384.72|                 0.0|                 0.0|      0|   CM|\n",
      "|   1|TRANSFER|    181.0|             181.0|               0.0|                 0.0|                 0.0|      1|   CC|\n",
      "|   1|CASH_OUT|    181.0|             181.0|               0.0|             21182.0|                 0.0|      1|   CC|\n",
      "|   1| PAYMENT| 11668.14|           41554.0|          29885.86|                 0.0|                 0.0|      0|   CM|\n",
      "|   1| PAYMENT|  7817.71|           53860.0|          46042.29|                 0.0|                 0.0|      0|   CM|\n",
      "|   1| PAYMENT|  7107.77|          183195.0|         176087.23|                 0.0|                 0.0|      0|   CM|\n",
      "|   1| PAYMENT|  7861.64|         176087.23|         168225.59|                 0.0|                 0.0|      0|   CM|\n",
      "|   1| PAYMENT|  4024.36|            2671.0|               0.0|                 0.0|                 0.0|      0|   CM|\n",
      "|   1|   DEBIT|  5337.77|           41720.0|          36382.23|             41898.0|            40348.79|      0|   CC|\n",
      "|   1|   DEBIT|  9644.94|            4465.0|               0.0|             10845.0|           157982.12|      0|   CC|\n",
      "|   1| PAYMENT|  3099.97|           20771.0|          17671.03|                 0.0|                 0.0|      0|   CM|\n",
      "|   1| PAYMENT|  2560.74|            5070.0|           2509.26|                 0.0|                 0.0|      0|   CM|\n",
      "|   1| PAYMENT| 11633.76|           10127.0|               0.0|                 0.0|                 0.0|      0|   CM|\n",
      "|   1| PAYMENT|  4098.78|          503264.0|         499165.22|                 0.0|                 0.0|      0|   CM|\n",
      "|   1|CASH_OUT|229133.94|           15325.0|               0.0|              5083.0|            51513.44|      0|   CC|\n",
      "|   1| PAYMENT|  1563.82|             450.0|               0.0|                 0.0|                 0.0|      0|   CM|\n",
      "|   1| PAYMENT|  1157.86|           21156.0|          19998.14|                 0.0|                 0.0|      0|   CM|\n",
      "|   1| PAYMENT|   671.64|           15123.0|          14451.36|                 0.0|                 0.0|      0|   CM|\n",
      "|   1|TRANSFER| 215310.3|             705.0|               0.0|             22425.0|                 0.0|      0|   CC|\n",
      "+----+--------+---------+------------------+------------------+--------------------+--------------------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop 'origin' and 'destination' columns\n",
    "df = df.drop(\"origin\", \"destination\")\n",
    "\n",
    "# Show the updated DataFrame\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- step: integer (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- sender_old_balance: double (nullable = true)\n",
      " |-- sender_new_balance: double (nullable = true)\n",
      " |-- receiver_old_balance: double (nullable = true)\n",
      " |-- receiver_new_balance: double (nullable = true)\n",
      " |-- isfraud: integer (nullable = true)\n",
      " |-- type2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "label_indexer = StringIndexer(inputCol=\"isfraud\", outputCol=\"label\")\n",
    "df = label_indexer.fit(df).transform(df)\n",
    "\n",
    "categorical_cols = [\"type\", \"type2\"]\n",
    "numerical_cols = [\"amount\", \"sender_old_balance\", \"sender_new_balance\",\n",
    "                  \"receiver_old_balance\", \"receiver_new_balance\"]\n",
    "\n",
    "# Pipeline stages\n",
    "stages = []\n",
    "\n",
    "# StringIndexer and OneHotEncoder for categorical features\n",
    "for col in categorical_cols:\n",
    "    indexer = StringIndexer(inputCol=col, outputCol=f\"indexed_{col}\")\n",
    "    encoder = OneHotEncoder(inputCol=f\"indexed_{col}\", outputCol=f\"encoded_{col}\")\n",
    "    stages.extend([indexer, encoder])\n",
    "\n",
    "# Assemble all features into a single vector\n",
    "assembler_inputs = [f\"encoded_{col}\" for col in categorical_cols] + numerical_cols\n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
    "stages.append(assembler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/21 15:42:04 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "[Stage 149:==========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Naïve Bayes Metrics:\n",
      "F1-Score: 0.9549\n",
      "Accuracy: 0.9161\n",
      "Precision: 0.9981\n",
      "Recall: 0.9161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Define Naïve Bayes model\n",
    "nb_classifier = NaiveBayes(labelCol=\"isfraud\", featuresCol=\"features\", modelType=\"multinomial\")\n",
    "\n",
    "# Add model to the pipeline\n",
    "nb_pipeline = Pipeline(stages=stages + [nb_classifier])\n",
    "\n",
    "# Split data into training and test sets\n",
    "training, test = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Hyperparameter tuning grid\n",
    "nb_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(nb_classifier.smoothing, [0.0, 1.0, 10.0]) \\\n",
    "    .build()\n",
    "\n",
    "# Cross-validation\n",
    "nb_cv = CrossValidator(\n",
    "    estimator=nb_pipeline,\n",
    "    estimatorParamMaps=nb_param_grid,\n",
    "    evaluator=MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"isfraud\", metricName=\"f1\"),\n",
    "    numFolds=3\n",
    ")\n",
    "\n",
    "# Train model\n",
    "nb_cv_model = nb_cv.fit(training)\n",
    "\n",
    "# Make predictions\n",
    "nb_predictions = nb_cv_model.transform(test)\n",
    "\n",
    "# Evaluate metrics\n",
    "nb_metrics = {\n",
    "    \"F1-Score\": MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"isfraud\", metricName=\"f1\").evaluate(nb_predictions),\n",
    "    \"Accuracy\": MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"isfraud\", metricName=\"accuracy\").evaluate(nb_predictions),\n",
    "    \"Precision\": MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"isfraud\", metricName=\"weightedPrecision\").evaluate(nb_predictions),\n",
    "    \"Recall\": MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"isfraud\", metricName=\"weightedRecall\").evaluate(nb_predictions),\n",
    "}\n",
    "\n",
    "# Print metrics\n",
    "print(\"\\n🔍 Naïve Bayes Metrics:\")\n",
    "for metric, value in nb_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
